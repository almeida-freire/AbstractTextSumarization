{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  NNModel:\n",
    "    \n",
    "    def  __init__(\n",
    "        self, vocab_size, batch_size, learning_rate, state_size, \n",
    "        num_layers, embedding_size, keep_prob, emb_init, epsilon,\n",
    "        dtype\n",
    "    ):\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.state_size = state_size \n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        self.keep_prob = keep_prob\n",
    "        self.emb_init = emb_init\n",
    "        self.epsilon = epsilon\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.model_objects = {}\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "    \n",
    "    def _init_placeholders(self):\n",
    "        self.model_objects[\"global_step\"] = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "        \n",
    "        self.model_objects[\"encoder_inputs\"] = tf.placeholder(tf.int32, shape=[self.batch_size, None])\n",
    "        self.model_objects[\"decoder_inputs\"] = tf.placeholder(tf.int32, shape=[self.batch_size, None])\n",
    "        self.model_objects[\"decoder_targets\"] = tf.placeholder(tf.int32, shape=[self.batch_size, None])\n",
    "        \n",
    "        self.model_objects[\"encoder_len\"] = tf.placeholder(tf.int32, shape=[self.batch_size])\n",
    "        self.model_objects[\"decoder_len\"] = tf.placeholder(tf.int32, shape=[self.batch_size])\n",
    "        \n",
    "        self.model_objects[\"beam_tok\"] = tf.placeholder(tf.int32, shape=[self.batch_size])\n",
    "        self.model_objects[\"prev_att\"] = tf.placeholder(tf.float32, shape=[self.batch_size, self.state_size * 2])\n",
    "\n",
    "    def _build_cells(self):\n",
    "        # TODO: Change to LSTM\n",
    "        encoder_fw_cell = tf.contrib.rnn.GRUCell(self.state_size)\n",
    "        encoder_bw_cell = tf.contrib.rnn.GRUCell(self.state_size)\n",
    "        decoder_cell = tf.contrib.rnn.GRUCell(self.state_size)\n",
    "\n",
    "        # bidirectional\n",
    "        self.model_objects[\"encoder_fw_cell\"] = tf.contrib.rnn.DropoutWrapper(\n",
    "            encoder_fw_cell, output_keep_prob=self.keep_prob\n",
    "        )\n",
    "        self.model_objects[\"encoder_bw_cell\"] = tf.contrib.rnn.DropoutWrapper(\n",
    "            encoder_bw_cell, output_keep_prob=self.keep_prob\n",
    "        )\n",
    "        self.model_objects[\"decoder_cell\"] = tf.contrib.rnn.DropoutWrapper(\n",
    "            decoder_cell, output_keep_prob=self.keep_prob\n",
    "        )\n",
    "        \n",
    "    def _seq2seq_embedding(self):\n",
    "            self.model_objects[\"embedding\"] = tf.get_variable(\n",
    "                \"embedding\", [self.vocab_size, self.embedding_size], initializer=self.emb_init\n",
    "            )\n",
    "       \n",
    "    def _seq2seq_encoder(self):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            encoder_inputs_emb = tf.nn.embedding_lookup(\n",
    "                self.model_objects[\"embedding\"], self.model_objects[\"encoder_inputs\"]\n",
    "            )\n",
    "\n",
    "            rnn_outs = tf.nn.bidirectional_dynamic_rnn(\n",
    "                self.model_objects[\"encoder_fw_cell\"], \n",
    "                self.model_objects[\"encoder_bw_cell\"], \n",
    "                encoder_inputs_emb,\n",
    "                sequence_length=self.model_objects[\"encoder_len\"], \n",
    "                dtype=self.dtype\n",
    "            )\n",
    "            self.model_objects[\"encoder_outputs\"], self.model_objects[\"encoder_states\"] = (\n",
    "                rnn_outs\n",
    "            )\n",
    "            \n",
    "    def _seq2seq_init_state(self):\n",
    "        with tf.variable_scope(\"init_state\"):\n",
    "            init_state = tf.contrib.layers.fully_connected(\n",
    "                tf.concat(self.model_objects[\"encoder_states\"], axis=1), \n",
    "                self.state_size\n",
    "            )\n",
    "            \n",
    "            # the shape of bidirectional_dynamic_rnn is weird\n",
    "            # None for batch_size\n",
    "            self.model_objects[\"init_state\"] = init_state\n",
    "            self.model_objects[\"init_state\"].set_shape([self.batch_size, self.state_size])\n",
    "            \n",
    "            self.model_objects[\"att_states\"] = tf.concat(\n",
    "                self.model_objects[\"encoder_outputs\"], axis=2\n",
    "            )\n",
    "            self.model_objects[\"att_states\"].set_shape(\n",
    "                [self.batch_size, None, self.state_size*2]\n",
    "            )\n",
    "            \n",
    "    def _seq2seq_attention(self):\n",
    "        with tf.variable_scope(\"attention\"):\n",
    "            attention = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                self.state_size, self.model_objects[\"att_states\"], \n",
    "                self.model_objects[\"encoder_len\"]\n",
    "            )\n",
    "            \n",
    "            self.model_objects[\"decoder_cell\"] = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                self.model_objects[\"decoder_cell\"], attention, self.state_size * 2\n",
    "            )\n",
    "            \n",
    "#             self.model_objects[\"wrapper_state\"] = tf.contrib.seq2seq.AttentionWrapperState(\n",
    "#                 self.model_objects[\"init_state\"], self.model_objects[\"prev_att\"]\n",
    "#             )\n",
    "\n",
    "            # TODO: Talvez tenha um problema aqui\n",
    "            self.model_objects[\"wrapper_state\"] = self.model_objects[\"decoder_cell\"].zero_state(\n",
    "                self.batch_size, self.dtype\n",
    "            ).clone(cell_state=self.model_objects[\"init_state\"])\n",
    "            \n",
    "    def _seq2seq_decoder(self):\n",
    "        with tf.variable_scope(\"decoder\") as scope:\n",
    "            decoder_inputs_emb = tf.nn.embedding_lookup(\n",
    "                self.model_objects[\"embedding\"], self.model_objects[\"decoder_inputs\"]\n",
    "            )\n",
    "\n",
    "            self.model_objects[\"decoder_cell\"] = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "                self.model_objects[\"decoder_cell\"], self.vocab_size\n",
    "            )\n",
    "\n",
    "            helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                decoder_inputs_emb, self.model_objects[\"decoder_len\"]\n",
    "            )\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                self.model_objects[\"decoder_cell\"], helper, \n",
    "                self.model_objects[\"wrapper_state\"]\n",
    "            )\n",
    "\n",
    "            outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "            self.model_objects[\"outputs\"] = outputs[0]\n",
    "\n",
    "    def _seq2seq_loss(self):\n",
    "        with tf.variable_scope(\"loss\") as scope:\n",
    "            weights = tf.sequence_mask(\n",
    "                self.model_objects[\"decoder_len\"], dtype=tf.float32\n",
    "            )\n",
    "\n",
    "            loss_t = tf.contrib.seq2seq.sequence_loss(\n",
    "                self.model_objects[\"outputs\"], self.model_objects[\"decoder_targets\"], weights,\n",
    "                average_across_timesteps=False,\n",
    "                average_across_batch=False\n",
    "            )\n",
    "\n",
    "            self.model_objects[\"loss\"] = tf.reduce_sum(loss_t) / self.batch_size\n",
    "\n",
    "            tf.summary.scalar('loss', self.model_objects[\"loss\"])\n",
    "            \n",
    "    def _seq2seq_optimize(self):\n",
    "        with tf.variable_scope(\"optimizer\") as scope:\n",
    "            self.model_objects[\"optimizer\"] = tf.train.AdadeltaOptimizer(\n",
    "                self.learning_rate, epsilon=self.epsilon\n",
    "            ).minimize(self.model_objects[\"loss\"])\n",
    "\n",
    "    def _build(self):\n",
    "        self._init_placeholders()\n",
    "        self._build_cells()\n",
    "        self._seq2seq_embedding()\n",
    "        self._seq2seq_encoder()\n",
    "        self._seq2seq_init_state()\n",
    "        self._seq2seq_attention()\n",
    "        self._seq2seq_decoder()\n",
    "        self._seq2seq_loss()\n",
    "        self._seq2seq_optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
